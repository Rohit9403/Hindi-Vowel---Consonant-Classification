{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vowel_Consonent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16IXBqKtXvUM74UxqdHKj56JeriHh3mFg",
      "authorship_tag": "ABX9TyPj4JQo3bdO+/oq4+tYtfpE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit9403/Hindi-Vowel---Consonant-Classification/blob/master/Vowel_Consonent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vieSGNkxJcFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/'My Drive'/PadhAI/train.zip /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxKtjLlwJ2du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6427sRYJ6Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/'My Drive'/PadhAI/test.zip /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls1ARHQRJ6eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8pMcKKlQLFt",
        "colab_type": "text"
      },
      "source": [
        "#DATA LOADER OF data set\n",
        "\n",
        "Link for the Dataset: [Kaggle Dataset](https://www.kaggle.com/c/padhai-hindi-vowel-consonant-classification/data\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djcGtVlsJ8sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import copy\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            label=torch.stack([z1,z2])\n",
        "\n",
        "            return image_data, label\n",
        "\n",
        "        else:\n",
        "            return image_data, file_name\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        return classes_mapping\n",
        "    \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "#transform = transforms.Compose([\n",
        "#    transforms.ToTensor()])\n",
        "transform = transforms.Compose([\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(), ])\n",
        "\n",
        "batch_size = 60\n",
        "full_data=VowelConsonantDataset(\"/content/train\",train=True,transform=transform)\n",
        "train_size = int(0.9 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "\n",
        "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_data=VowelConsonantDataset(\"/content/test\",train=False,transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=60,shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_lYgUHHKJSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c4e4bef-fcb7-4963-ee82-e7b8efc5c029"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_3CGYelQSOU",
        "colab_type": "text"
      },
      "source": [
        "#Model Architecture\n",
        "\n",
        "Mobilenet V2 + 2 Fully connected layer with output features of 10 classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pivJJ6pAKPLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugd1k-ZMKP7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes1, num_classes2):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.model_snet = models.mobilenet_v2(pretrained=True)\n",
        "        final_in_features = self.model_snet.classifier[1].in_features\n",
        "        mod_classifier = list(self.model_snet.classifier.children())[:-1]\n",
        "        self.model_snet.classifier = nn.Sequential(*mod_classifier)\n",
        "\n",
        "        self.fc1 = nn.Linear(final_in_features, num_classes1,bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        torch.nn.init.zeros_(self.fc1.bias)\n",
        "        self.fc2 = nn.Linear(final_in_features, num_classes2,bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        torch.nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model_snet(x)\n",
        "        out1 = self.fc1(x)\n",
        "        out2 = self.fc2(x)\n",
        "        return out1, out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-n1EMNBKZ4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net  = MyModel(10,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2IUCzecRDSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "058962f5-c151-4e87-9475-e816c12c1f36"
      },
      "source": [
        "print(net)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyModel(\n",
            "  (model_snet): MobileNetV2(\n",
            "    (features): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (7): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (12): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (13): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (14): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (15): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (16): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (17): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (18): ConvBNReLU(\n",
            "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (classifier): Sequential(\n",
            "      (0): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (fc1): Linear(in_features=1280, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=1280, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYEVrO6dROX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for param in net.model_snet.parameters():\n",
        "  #param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWZ1PMP2RkUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40abf8eb-002d-4e74-cebb-97dafa283209"
      },
      "source": [
        "for param in net.parameters():\n",
        "    if param.requires_grad:\n",
        "        print(param.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 3, 3])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([32, 1, 3, 3])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([16, 32, 1, 1])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "torch.Size([96, 16, 1, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 1, 3, 3])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([24, 96, 1, 1])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([144, 24, 1, 1])\n",
            "torch.Size([144])\n",
            "torch.Size([144])\n",
            "torch.Size([144, 1, 3, 3])\n",
            "torch.Size([144])\n",
            "torch.Size([144])\n",
            "torch.Size([24, 144, 1, 1])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([144, 24, 1, 1])\n",
            "torch.Size([144])\n",
            "torch.Size([144])\n",
            "torch.Size([144, 1, 3, 3])\n",
            "torch.Size([144])\n",
            "torch.Size([144])\n",
            "torch.Size([32, 144, 1, 1])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([192, 32, 1, 1])\n",
            "torch.Size([192])\n",
            "torch.Size([192])\n",
            "torch.Size([192, 1, 3, 3])\n",
            "torch.Size([192])\n",
            "torch.Size([192])\n",
            "torch.Size([32, 192, 1, 1])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([192, 32, 1, 1])\n",
            "torch.Size([192])\n",
            "torch.Size([192])\n",
            "torch.Size([192, 1, 3, 3])\n",
            "torch.Size([192])\n",
            "torch.Size([192])\n",
            "torch.Size([32, 192, 1, 1])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([192, 32, 1, 1])\n",
            "torch.Size([192])\n",
            "torch.Size([192])\n",
            "torch.Size([192, 1, 3, 3])\n",
            "torch.Size([192])\n",
            "torch.Size([192])\n",
            "torch.Size([64, 192, 1, 1])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([384, 64, 1, 1])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([384, 1, 3, 3])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([64, 384, 1, 1])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([384, 64, 1, 1])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([384, 1, 3, 3])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([64, 384, 1, 1])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([384, 64, 1, 1])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([384, 1, 3, 3])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([64, 384, 1, 1])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([384, 64, 1, 1])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([384, 1, 3, 3])\n",
            "torch.Size([384])\n",
            "torch.Size([384])\n",
            "torch.Size([96, 384, 1, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([576, 96, 1, 1])\n",
            "torch.Size([576])\n",
            "torch.Size([576])\n",
            "torch.Size([576, 1, 3, 3])\n",
            "torch.Size([576])\n",
            "torch.Size([576])\n",
            "torch.Size([96, 576, 1, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([576, 96, 1, 1])\n",
            "torch.Size([576])\n",
            "torch.Size([576])\n",
            "torch.Size([576, 1, 3, 3])\n",
            "torch.Size([576])\n",
            "torch.Size([576])\n",
            "torch.Size([96, 576, 1, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([576, 96, 1, 1])\n",
            "torch.Size([576])\n",
            "torch.Size([576])\n",
            "torch.Size([576, 1, 3, 3])\n",
            "torch.Size([576])\n",
            "torch.Size([576])\n",
            "torch.Size([160, 576, 1, 1])\n",
            "torch.Size([160])\n",
            "torch.Size([160])\n",
            "torch.Size([960, 160, 1, 1])\n",
            "torch.Size([960])\n",
            "torch.Size([960])\n",
            "torch.Size([960, 1, 3, 3])\n",
            "torch.Size([960])\n",
            "torch.Size([960])\n",
            "torch.Size([160, 960, 1, 1])\n",
            "torch.Size([160])\n",
            "torch.Size([160])\n",
            "torch.Size([960, 160, 1, 1])\n",
            "torch.Size([960])\n",
            "torch.Size([960])\n",
            "torch.Size([960, 1, 3, 3])\n",
            "torch.Size([960])\n",
            "torch.Size([960])\n",
            "torch.Size([160, 960, 1, 1])\n",
            "torch.Size([160])\n",
            "torch.Size([160])\n",
            "torch.Size([960, 160, 1, 1])\n",
            "torch.Size([960])\n",
            "torch.Size([960])\n",
            "torch.Size([960, 1, 3, 3])\n",
            "torch.Size([960])\n",
            "torch.Size([960])\n",
            "torch.Size([320, 960, 1, 1])\n",
            "torch.Size([320])\n",
            "torch.Size([320])\n",
            "torch.Size([1280, 320, 1, 1])\n",
            "torch.Size([1280])\n",
            "torch.Size([1280])\n",
            "torch.Size([10, 1280])\n",
            "torch.Size([10])\n",
            "torch.Size([10, 1280])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax3CXBEFKcry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOM48jjBQlI9",
        "colab_type": "text"
      },
      "source": [
        "#model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyXmTHuAKjDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader):\n",
        "    \n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Extracting Actual Labels\n",
        "        _, actual_v = torch.max(labels[:,0,:].data, 1)\n",
        "        _, actual_c = torch.max(labels[:,1,:].data, 1)\n",
        "        \n",
        "        outputs_v,outputs_c = net(inputs)\n",
        "        _, pred_v = torch.max(outputs_v.data, 1)\n",
        "        _, pred_c = torch.max(outputs_c.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct_v = (pred_v == actual_v)*1\n",
        "        correct_c = (pred_c == actual_c)*1\n",
        "        correct_v[correct_v == 0] = 2\n",
        "        correct_c[correct_c == 0] = 3\n",
        "        correct += ((correct_v==correct_c)).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTlwmkHDQp5u",
        "colab_type": "text"
      },
      "source": [
        "#Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMKmD-fgKoja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "plist = [\n",
        "        {'params': net.fc1.parameters(), 'lr': 5e-3},\n",
        "        {'params': net.fc2.parameters(), 'lr': 5e-3}\n",
        "        ]\n",
        "lr=0.01\n",
        "opt = optim.SGD(net.parameters(),lr=0.01,momentum=0.9,nesterov=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79vuUlyRKsNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "1c494aaa-7d01-456c-c02f-dc52f3ff4ccd"
      },
      "source": [
        "%%time\n",
        "loss_arr = []\n",
        "loss_epoch_arr = []\n",
        "max_epochs = 10\n",
        "min_loss = 1000\n",
        "best_model = None\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        labels_v = labels[:,0,:]\n",
        "        labels_c = labels[:,1,:]\n",
        "        _, actual_v = torch.max(labels_v.data, 1)\n",
        "        _, actual_c = torch.max(labels_c.data, 1)\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs_v, outputs_c = net(inputs)\n",
        "        loss_v = loss_fn(outputs_v, actual_v)\n",
        "        loss_c = loss_fn(outputs_c, actual_c)\n",
        "        loss = torch.add(loss_v,loss_c)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        if min_loss > loss.item():\n",
        "            min_loss = loss.item()\n",
        "            best_model = copy.deepcopy(net.state_dict())\n",
        "        \n",
        "        loss_arr.append(loss.item())\n",
        "        \n",
        "        del inputs, labels, outputs_v, outputs_c\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch, max_epochs, evaluation(validation_loader), evaluation(train_loader)))\n",
        "  \n",
        "\n",
        "net.load_state_dict(best_model)\n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.plot(loss_arr)\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/10, Test acc: 69.40, Train acc: 70.54\n",
            "Epoch: 1/10, Test acc: 72.30, Train acc: 76.92\n",
            "Epoch: 2/10, Test acc: 76.60, Train acc: 81.73\n",
            "Epoch: 3/10, Test acc: 77.90, Train acc: 82.81\n",
            "Epoch: 4/10, Test acc: 78.20, Train acc: 86.12\n",
            "Epoch: 5/10, Test acc: 78.60, Train acc: 87.63\n",
            "Epoch: 6/10, Test acc: 79.00, Train acc: 88.13\n",
            "Epoch: 7/10, Test acc: 80.70, Train acc: 90.07\n",
            "Epoch: 8/10, Test acc: 78.90, Train acc: 91.10\n",
            "Epoch: 9/10, Test acc: 80.60, Train acc: 91.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8min 5s, sys: 4min 11s, total: 12min 17s\n",
            "Wall time: 12min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc-c8pemQ28D",
        "colab_type": "text"
      },
      "source": [
        "#Predicting Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9K_VrkK9-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.eval()\n",
        "plist=[]\n",
        "fn_list=[]\n",
        "for inputs_test, fn in test_loader:\n",
        "    inputs_test=inputs_test.to(device)\n",
        "    out1,out2=net.forward(inputs_test)\n",
        "    _,pred1=torch.max(out1,1)\n",
        "    pred1=pred1.tolist()\n",
        "    _,pred2=torch.max(out2,1)\n",
        "    pred2=pred2.tolist()\n",
        "    for x,y,z in zip(pred1,pred2,fn):\n",
        "        p=\"V\"+str(x)+\"_\"+\"C\"+str(y)\n",
        "        plist.append(p)\n",
        "        fn_list.append(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDSE_8H_LIhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9610e10c-5f24-48f7-d672-5b6557c6aec7"
      },
      "source": [
        "submission = pd.DataFrame({\"ImageId\":fn_list, \"Class\":plist})\n",
        "submission.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1163.png</td>\n",
              "      <td>V1_C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>784.png</td>\n",
              "      <td>V0_C7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>640.png</td>\n",
              "      <td>V0_C9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9665.png</td>\n",
              "      <td>V9_C6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3687.png</td>\n",
              "      <td>V3_C6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ImageId  Class\n",
              "0  1163.png  V1_C1\n",
              "1   784.png  V0_C7\n",
              "2   640.png  V0_C9\n",
              "3  9665.png  V9_C6\n",
              "4  3687.png  V3_C6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA1k-2vLQcuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}